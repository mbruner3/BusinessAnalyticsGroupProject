---
title: "Business Analytics Group Project  \n Group 1"
author: "Khushboo Yadav  \n Mark Bruner  \n Rakhee Moolchandani  \n Mayank Pugalia  \n Tanmoy Kanti Kumar"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document: default
  html_document: default
  word_document: default
---


\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

rm(list=ls()) # This code will clear your environment each time you run all. 
```

#### **Importing Libraries**

```{r, warning = FALSE,message=FALSE, echo=FALSE}
library(plyr) # for data manipulation
library(tidyverse) # for visualizations, data pre-processing, and data manipulation
library(caret) #for data splitting, modeling tuning, pre-processing
library(party) # for decision tree
library(ggcorrplot) # for correlations.
library(stats) # for the step-wise search.
library(rpart) # for decision tree
library(rpart.plot) #for decision tree
library(mice) # for Imputation for NA values
library(VIM) # for plotting the amount of missing values
```

#### **Loading and Reading the Dataset**  

```{r, results=FALSE, message=FALSE}
# Loading the training data to analyze and build the model.
Churn_Train <- read_csv("~/Documents/BusinessAnalyticsGroupProject/R code and Script/Churn_Train.csv")

# Loading the file containing the list of consumers that we need to predict their future churn.
load("~/Documents/BusinessAnalyticsGroupProject/R code and Script/Customers_To_Predict.RData") 

# Removed the "area_code_" part of the string in "area_code" variable.
Churn_Train$area_code <- as.factor(sub("area_code_", "", Churn_Train$area_code)) 
Customers_To_Predict <- Custmers_to_predict # Remove this...
Customers_To_Predict$area_code <- as.factor(sub("area_code_", 
                                                "", 
                                                Customers_To_Predict$area_code))
```

# **Part 1: Cleaning & Wrangling Data**

```{r, echo=FALSE}
summary(Churn_Train)
```

####  **A. Discovering NA Values**

```{r}
sapply(Churn_Train, function(x) sum(is.na(x))) # Shows the NA data
```

The current dataset, Churn_Train, has many NA values. We will impute the missing values into the dataset so that we can retain the useful information. We also don't want the missing values to impact the data analysis and the model predictions.

```{r}
sapply(Customers_To_Predict, function(x) sum(is.na(x))) # Shows the no NA data
```

Our test dataset does not have any missing values.

```{r}
md.pattern(Churn_Train,rotate.names = TRUE) # See the missing value pattern
# Plot the missing values

aggr(Churn_Train, col = mdc(1:2), numbers = TRUE, sortVars = TRUE, labels = names(Churn_Train), cex.axis = .7, gap = 3, ylab = c("Proportion of Missingness", "Missing Pattern"))
```



**Imputation Method Discussion**
We have decided to use the mice::mice() function to impute the NA values. The reason we choose this function is because it creates multiple imputations as compared to single imputations (such as using the mean) which, we believe, will lead to better imputation values.

#### **B. Imputing the Missing Values**

```{r, results=FALSE, warning=FALSE}
Churn_Train <- mice(Churn_Train, diagnostics=FALSE,remove_collinear = FALSE)
Churn_Train <- complete(Churn_Train, 5)
colMeans(is.na(Churn_Train)) # Validating the NA values after applying mice() on the dataset
```

# **Part 2. Exploratory Data Analysis**

#### **A. Looking for Outliers**

```{r,fig.width=6, fig.align='center'}
boxplot(Churn_Train[, 6:19])
```
**Interpretation of Boxplot:**
The boxplot graphs above show that most of the variables in the Churn_Train dataset are normally distributed with an exception of "total day minutes" and "total evening minutes" which has some outliers that may need to be removed. We will explore these two variables later.

#### **B. Variables Data Shape**    
The histograms below show the distribution for each variable.

```{r}
Churn_Train[, 6:19] %>% 
  gather(key = Variable, value = Value) %>% 
  ggplot() +
    geom_histogram(aes(x = Value), fill = "steelblue") +
    facet_wrap(~Variable, scales='free') +
    theme_classic() +
    theme(aspect.ratio = 0.5, axis.title = element_blank(), panel.grid = element_blank())

```
**Interpretation:**
We can clearly see the beautiful bell curve distribution of data for most of the variables. 

"Total day minutes" and "total evening minutes" has a small number of outliers which we mentioned earlier. Since both of those variables have similar shapes and outlier pattern, we believe that this data came from older cellular company which many of them had plans where you were charged more for total minutes until a certain point and then it was free. We believe that these represent the charging structure of the cell phone plans which explains the gap in the data. The "Customer Service Calls" data is skewed negatively. 


```{r}
Churn_Train %>% 
  filter(churn == "yes") %>%
  ggplot(mapping = aes(x = number_customer_service_calls)) +
  geom_histogram(aes(fill = churn), binwidth = 1) 
# Showing the number of customer service calls per churned customer.

Churn_Train %>% 
  group_by(churn) %>% 
  tally(churn == "yes") 
# total churned in data set.

Churn_Train %>% 
  filter(churn == "yes" 
         & number_customer_service_calls >= 1 
         & number_customer_service_calls <= 4) %>% 
  tally()/483 
# 67% of all the customers who churned made 1 to 4 calls to customer service.
 
Churn_Train %>% 
  filter(churn == "yes") %>%
  ggplot(mapping = aes(x = international_plan)) +
  geom_histogram(aes(fill = churn), stat = "count")

Churn_Train %>% 
  group_by(international_plan) %>% 
  filter(churn == "yes") %>% 
  select(international_plan) %>% 
  dplyr:: summarise("Churn Count" =n(), "Percent" = n()/483)
# 28% of all international plan subscribers will churn.

Churn_Train %>% 
  filter(churn == "yes") %>%
  ggplot(mapping = aes(x = number_customer_service_calls)) +
  geom_histogram(aes(fill = international_plan ), binwidth = .5)
# Most people churned making 0 to 2 calls to customer service. 
#The fact that about 30% of those who churned between 0 and 2 calls did so at making 0 calls 
# means there are other reasons for their churning.
```

#### **C. Correlation Between Variables**

We will analyze the correlation of variables first with the entire dataset and then subset the data to include those customers who churned to see if there are any clues to what may cause the customers to churn.

```{r}
Churn_Train %>% 
  filter(churn=="yes") -> churn
cor(Churn_Train[, 6:19]) -> cc
cor(churn[, 6:19]) ->cc2

# Correlation of the complete dataset.
ggcorrplot(cc, method = "circle", type = "lower", ggtheme = theme_classic)

# Correlation of those customers who churned.
ggcorrplot(cc2, method = "circle", type = "lower", ggtheme = theme_classic)
```

#### **Interpretation of the correlation chart:**

##### **Correlations of the Complete Dataset**

* **Positive Relation:** 

  + total evening  minutes and total day minutes
  + total evening charges and total evening minutes
  + total night charges and total night minutes
  + total international charge and total international minutes



##### **Churned Customers Dataset**

* **Positive Correlation:**

  + total evening minutes and total day minutes
  + total night charge and total night minutes
  + total international charge and total international minutes


* **Negative Correlation:**
 
  + number customer service calls and total day charge,total evening charge,total night minutes,total international calls and charges
  + total day charge and number of voice mail messages
  + total evening charges and total evening charge
  + total night charge and  total day charge


The variables with a strong negative correlation are between total day minutes and total evening minutes. What this means is that as the evening minutes increase the total day minutes decrease. Also, a slight negative correlation between the total evening minutes and the total evening charges. 

Looking at the correlation of just the people who churned, some potentially interesting information appeared. There is a strong correlation between the totals day charges and the number of Customer Service Calls. The higher the charges the more calls were made. The same was true for customer service calls and total evening charges although less of a relationship compared to day charges. 

We will analyze this data in more detail for total day calls, the number of customer service calls, and the total day charge.

```{r}
Churn_Train %>% 
  filter(churn=="yes") %>% 
  ggplot(mapping = aes(x = total_day_calls)) +
  geom_histogram(aes(fill = churn))

Churn_Train %>% 
  filter(churn=="yes") %>% 
  ggplot(mapping = aes(x = number_customer_service_calls)) +
  geom_histogram(aes(fill = churn))


Churn_Train %>% 
  filter(churn=="yes") %>% 
  ggplot(mapping = aes(x = total_day_charge)) +
  geom_histogram(aes(fill = churn))
```

Most of the people seem to churn between 75 to 125 calls per day, making 1 to 5 customer service calls, and when the charges are between 10 and 60 per day. 

Based on the above, I might suggest that the reason people are churning is that the cost of daily phone call charges during the day are too much. FYI I think this data is really old as I remember when Cell Phone companies used to charge more for calls made during the day than the evening.

# Part 3. Data Pre-Processing and Model Building

#### Data Type Updating
```{r}
# 1. Updating the values of churn to 1 or 0
Churn_Train$churn<- ifelse(Churn_Train$churn=="yes", 1, 0)


# 2. Factorization of Churn_Train data
Churn_Train$area_code<- as.factor(Churn_Train$area_code) # added because of decision trees
Churn_Train$state<- as.factor(Churn_Train$state)
Churn_Train$international_plan<-as.factor(Churn_Train$international_plan)
Churn_Train$voice_mail_plan <-as.factor(Churn_Train$voice_mail_plan)
Churn_Train$churn<- as.factor(Churn_Train$churn)


# 3. Validating the structure of the Churn_Train data
str(Churn_Train)

```

#### A. Choice of Models Discussion:
Decision trees and logistic regression are two popular algorithms and can be used for customer churn prediction. These models are especially useful for classification problems and they also are easily understood.

We will be using both classification models to build our customer churn prediction model. We will then assess which model has better performance in predicting churn and use that model on our test dataset.


#### **B. Logistic Regression and Decision Trees Model Building:**

##### **Steps to Model Building:**

1. Partitioning the Churn_Train data into train_data and validation_data.

2. Building Decision Tree model with the train_data and then:
    i. Use the model on the validation dataset
    ii. Validate the performance of the predictions from the model to the actual results using a confusion matrix

3. Building Decision Tree model with the train_data and then:
    i. Use the model on the validation dataset
    ii. Validate the performance of the predictions from the model to the actual results using a confusion matrix

4. Compare the confusion matrix for both models and select the model that performs the best. We will be using the Specificity metric to determine the model's performance because it measures ("1") percent of people the model correctly predicted will churn and actually churned.

#### **C. Churn Train Data Partitioning (60%,40%)**

```{r}
set.seed(2020)
partition<- createDataPartition(Churn_Train$churn,p=0.6,list=FALSE)

train_data<- Churn_Train[partition,]
validation_data<- Churn_Train[-partition,]
```

#### **D. Building Decision Tree Model: **

```{r}
# Decision Tree Model Building
DecisionTree_model <- ctree(churn~ ., train_data[,-1]) #not including state column
pred_tree <- predict(DecisionTree_model, validation_data)

#Prediction table
table(pred_tree)

```
#### **E. Confusion Matrix for Decision Tree Model Predictions**

```{r}
# Confusion Matrix
confusionMatrix(pred_tree,validation_data$churn)
```



####  F. Building Logistic Regression Model:

```{r}
# Note: Model performance was improved after removing "states"

## Applying logistic regression model 
Logistic_Model <- glm(churn ~ .,family=binomial(link="logit"),data=train_data[,-1])
summary(Logistic_Model)

## Predicting churn results based on the logistic model
predict_validation<-predict(Logistic_Model,newdata = validation_data,type='response')

## Categorizing the result based on the cutoff value(0.5)
resultcheck<-ifelse(predict_validation>0.5,1,0)
```



####  G. Building Improvised Logistic Regression Models

```{r}
Logistic_Model2 <-glm(formula = churn ~ account_length + area_code + international_plan + 
    voice_mail_plan + number_vmail_messages + total_day_minutes + 
    total_day_calls + total_day_charge + total_eve_minutes + 
    total_eve_charge + total_night_minutes + total_night_charge + 
    total_intl_minutes + total_intl_calls + number_customer_service_calls + 
    total_day_charge:number_customer_service_calls + total_day_charge:total_eve_charge + 
    voice_mail_plan:total_day_charge + international_plan:total_intl_minutes + 
    international_plan:number_customer_service_calls + total_eve_charge:number_customer_service_calls + 
    total_day_charge:total_night_charge + international_plan:total_intl_calls + 
    area_code:number_vmail_messages + voice_mail_plan:total_intl_calls + 
    total_intl_calls:number_customer_service_calls + total_day_calls:total_eve_charge + 
    number_vmail_messages:total_intl_calls + international_plan:total_day_calls + 
    voice_mail_plan:total_night_charge + total_night_minutes:number_customer_service_calls + 
    total_eve_charge:total_intl_calls + voice_mail_plan:total_eve_charge + 
    total_eve_charge:total_night_minutes + total_day_charge:total_intl_calls + 
    area_code:total_day_minutes + international_plan:total_eve_minutes + 
    international_plan:total_day_minutes + international_plan:total_eve_charge + 
    total_night_minutes:total_night_charge, family = binomial(link = "logit"), 
    data = train_data)

#summary
summary(Logistic_Model2)

#Predicting the validation data based on the improvised  logistic Regression model
predict_validation2<-predict(Logistic_Model2,newdata = validation_data,type='response')

#Classify the data based on the value greater than 0.5 and saving into a folder.
resultcheck2<-ifelse(predict_validation2>0.5,1,0)
```

# **Part 4. Logistic and Decision Treee Model Performance Assessment**

#### A. **Model Accuracy**
```{r}
##Logistic method
error<-mean(resultcheck!=validation_data$churn)
accuracy<-1-error
print(accuracy)


#improvised model for logistic regression
error2<-mean(resultcheck2!=validation_data$churn)
accuracy2<-1-error2
print(accuracy2)
```

**Result Summary:**
The accuracy of the improvised model using the step() function has better results with Accuracy = 90%.

#### **B. ROC for Logistic Regression**
```{r}
library(pROC)
#ROC Curve for validation Data set with Logistic Model
roc(validation_data$churn, predict_validation)
plot.roc(validation_data$churn,predict_validation,col = "red", lwd = 3)

#ROC Curve for validation Data set with Improvised Logistic Model
roc(validation_data$churn, predict_validation2)
plot.roc(validation_data$churn,predict_validation2,col = "red", lwd = 3)
```

#### **C. Logistic Regression Confusion Matrices**

```{r}
# Logistic Regression Confusion Matrix
resultcheck<- as.factor(resultcheck)
confusionMatrix(resultcheck,validation_data$churn)

# Improvised Logistic Regression Model Confusion Matrix
resultcheck2<- as.factor(resultcheck2)
confusionMatrix(resultcheck2, validation_data$churn)

# Anova
anova(Logistic_Model,Logistic_Model2, test="Chisq")
```

**Model Selection Discussion:**

1. Based on Anova model comparison and the confusion matrices results, we can say that the performance has improved significantly by the improvised model. The specificity improved by 25 percent. Therefore, we will consider the improvised logistic regression model as the best logistic model based on specificity.


2. The Improvised Logistic Model Specificity is good but the Decision Tree has a Specificity of 71% which is an improvement of almost 30%! 


**Model Comparison result:**

As per the targeted approach that the company will be trying to identify the customers who are likely to churn, Specificity is the top criteria for the model selection as discussed earlier.

Therefore, we are choosing the Decision Tree Model as the best model to predict the customers who are likely to churn. 

# Part 5. Predicting Customers who will Churn:

```{r, warning = FALSE, fig.width=7.5, fig.align='center'}

# Converting the data type Churn_Train according to the Customers_To_Predict
Churn_Train[, c(2,6,8,11,14,17,19)] <- as.integer(unlist(Churn_Train[, c(2,6,8,11,14,17,19)]))

# Building the model on the Churn_Train dataset using ctree()
Model_ABC_Wireless <- ctree(Churn_Train$churn~ ., Churn_Train[,-1])

# Predicting churn results based on the Decision Tree Model
predict_validation <- predict(Model_ABC_Wireless, newdata = Customers_To_Predict, type='response')

table(predict_validation)

predict_validation <- as.data.frame(predict_validation)

# Plotting Decision Tree
dcplot<-rpart(Churn_Train$churn ~.,data=Churn_Train,method='class')
rpart.plot(dcplot,extra=106)
plot(Model_ABC_Wireless, type='simple')

# plotting the prediction results :
predict_validation %>% 
  ggplot(aes(x = `predict_validation`)) +
  geom_histogram(stat = "count", fill = "orange") +
  labs(x = "Customer Churn Or Not", y = "# of Customers")+
  ggtitle(" Number of Customers likely to Churn") +
  theme(plot.title = element_text(hjust =.5, size = 16, face = c("bold", "italic")))
```

#### **Concluding Summary**
Our model predicted that 93 of the 1000 customers in the dataset will churn. 
